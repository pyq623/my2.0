import os
import json
import argparse
import time
from datetime import datetime, timedelta
from configs import get_search_space

# è®¾ç½®æ—¶åŒºä¸ºä¸­å›½åŒ—äº¬æ—¶åŒº
os.environ['TZ'] = 'Asia/Shanghai'
time.tzset()

# å¯¼å…¥æ–°çš„å¹¶è¡Œæœç´¢ç±»
import sys
sys.path.insert(0, os.path.dirname(__file__))
from mcts import create_parallel_sfs_search

class Timer:
    """è®¡æ—¶å™¨ç±»"""
    def __init__(self, name: str = ""):
        self.name = name
        self.start_time = None
        self.end_time = None
        self.elapsed = 0
        
    def start(self):
        """å¼€å§‹è®¡æ—¶"""
        self.start_time = time.time()
        return self
    
    def stop(self):
        """åœæ­¢è®¡æ—¶"""
        self.end_time = time.time()
        self.elapsed = self.end_time - self.start_time
        return self.elapsed
    
    def __enter__(self):
        """æ”¯æŒ with è¯­å¥"""
        self.start()
        return self
    
    def __exit__(self, *args):
        """é€€å‡º with è¯­å¥æ—¶è‡ªåŠ¨åœæ­¢"""
        self.stop()
    
    def get_elapsed_str(self) -> str:
        """è·å–æ ¼å¼åŒ–çš„è€—æ—¶å­—ç¬¦ä¸²"""
        return self.format_time(self.elapsed)
    
    @staticmethod
    def format_time(seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        if seconds < 60:
            return f"{seconds:.2f}ç§’"
        elif seconds < 3600:
            minutes = seconds / 60
            return f"{minutes:.2f}åˆ†é’Ÿ ({seconds:.1f}ç§’)"
        else:
            hours = seconds / 3600
            minutes = (seconds % 3600) / 60
            return f"{hours:.2f}å°æ—¶ ({minutes:.1f}åˆ†é’Ÿ)"

def setup_search_space(dataset_name: str = "MMAct") -> dict:
    """è®¾ç½®æœç´¢ç©ºé—´"""
    info = get_search_space()
    search_space = info['search_space']
    constraints = info['constraints']
    return search_space, constraints

def create_output_directory(experiment_name: str) -> str:
    """åˆ›å»ºè¾“å‡ºç›®å½•"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = f"results/{experiment_name}_{timestamp}"
    os.makedirs(output_dir, exist_ok=True)
    return output_dir

def save_search_results(search, output_dir: str, args: dict, timing_stats: dict):
    """ä¿å­˜æœç´¢ç»“æœ"""
    # ä¿å­˜æœ€ä½³æ¨¡å‹é…ç½®
    best_model = search.get_best_model()
    if best_model:
        # âœ… ä»æ ‘ä¸­æŸ¥æ‰¾å¯¹åº”èŠ‚ç‚¹ä»¥è·å–æ·±åº¦ä¿¡æ¯
        best_node = None
        for node_id, node in search.tree.nodes.items():
            if node.candidate and node.candidate.candidate_id == best_model.candidate_id:
                best_node = node
                break
        
        # âœ… è®¡ç®—æ·±åº¦ï¼ˆå¦‚æœæ‰¾åˆ°èŠ‚ç‚¹ï¼‰
        depth = 0
        if best_node:
            current = best_node
            while current.parent and not current.parent.is_forest_root:
                depth += 1
                current = current.parent
            if current.parent:  # å¦‚æœæœ‰çˆ¶èŠ‚ç‚¹ä¸”çˆ¶èŠ‚ç‚¹æ˜¯æ ¹ï¼Œæ·±åº¦+1
                depth += 1
        
        # âœ… æ”¶é›†å®Œæ•´çš„å…ƒä¿¡æ¯
        best_model_data = {
            "config": best_model.config,
            "performance": {
                "reward": search.best_reward,
                "accuracy": best_model.metrics.get('accuracy', 0.0),
                "latency": best_model.metrics.get('latency', 0.0),
                "peak_memory": best_model.metrics.get('peak_memory', 0.0),
                "gpu_id": best_model.metrics.get('gpu_id', -1)
            },
            "metadata": {
                "candidate_id": best_model.candidate_id if hasattr(best_model, 'candidate_id') else 'unknown',
                "iteration_discovered": getattr(best_model, 'iteration', 'unknown'),
                "parent_seed_id": getattr(best_model, 'root_seed_id', 'unknown'),
                "depth_from_seed": depth,
                "parent_node_id": getattr(best_model, 'parent_id', None),
                "parent_direction": getattr(best_model, 'parent_direction', None)
            },
            "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }

        best_config_path = os.path.join(output_dir, "best_model_config.json")
        with open(best_config_path, 'w') as f:
            json.dump(best_model_data, f, indent=2, ensure_ascii=False)
        print(f"âœ… æœ€ä½³æ¨¡å‹é…ç½®å·²ä¿å­˜: {best_config_path}")
    
    # ä¿å­˜æœç´¢ç»Ÿè®¡ä¿¡æ¯ï¼ˆåŒ…å«è®¡æ—¶ä¿¡æ¯ï¼‰
    stats = search.get_search_statistics()
    stats['timing'] = timing_stats  # æ·»åŠ è®¡æ—¶ç»Ÿè®¡
    
    stats_path = os.path.join(output_dir, "search_statistics.json")
    with open(stats_path, 'w') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False, default=str)
    print(f"âœ… æœç´¢ç»Ÿè®¡å·²ä¿å­˜: {stats_path}")
    
    # ä¿å­˜æœç´¢çŠ¶æ€
    state_path = os.path.join(output_dir, "search_state.json")
    search.save_search_state(state_path)
    print(f"âœ… æœç´¢çŠ¶æ€å·²ä¿å­˜: {state_path}")
    
    # ä¿å­˜å®éªŒå‚æ•°ï¼ˆåŒ…å«è®¡æ—¶ä¿¡æ¯ï¼‰
    experiment_data = {
        'args': args,
        'timing': timing_stats
    }
    args_path = os.path.join(output_dir, "experiment_args.json")
    with open(args_path, 'w') as f:
        json.dump(experiment_data, f, indent=2, ensure_ascii=False)
    print(f"âœ… å®éªŒå‚æ•°å·²ä¿å­˜: {args_path}")
    
    # å•ç‹¬ä¿å­˜è®¡æ—¶æŠ¥å‘Š
    timing_report_path = os.path.join(output_dir, "timing_report.txt")
    with open(timing_report_path, 'w', encoding='utf-8') as f:
        f.write("="*60 + "\n")
        f.write("â±ï¸  è¿è¡Œæ—¶é—´ç»Ÿè®¡æŠ¥å‘Š\n")
        f.write("="*60 + "\n\n")
        
        f.write(f"ğŸ• æ€»è¿è¡Œæ—¶é—´: {Timer.format_time(timing_stats['total_time'])}\n\n")
        
        f.write("ğŸ“Š å„é˜¶æ®µè€—æ—¶:\n")
        f.write(f"  1. åˆå§‹åŒ–é˜¶æ®µ: {Timer.format_time(timing_stats['initialization_time'])}\n")
        f.write(f"  2. æ£®æ—åˆå§‹åŒ–: {Timer.format_time(timing_stats['forest_init_time'])}\n")
        f.write(f"  3. æœç´¢æ‰§è¡Œ:   {Timer.format_time(timing_stats['search_time'])}\n")
        f.write(f"  4. ç»“æœä¿å­˜:   {Timer.format_time(timing_stats['save_time'])}\n\n")
        
        f.write("ğŸ“ˆ æœç´¢æ•ˆç‡:\n")
        f.write(f"  - æ€»è¿­ä»£æ¬¡æ•°: {timing_stats['total_iterations']}\n")
        f.write(f"  - å¹³å‡æ¯æ¬¡è¿­ä»£: {Timer.format_time(timing_stats['avg_iteration_time'])}\n")
        
        if timing_stats['total_iterations'] > 0:
            throughput = 3600 / timing_stats['avg_iteration_time']  # æ¯å°æ—¶è¿­ä»£æ•°
            f.write(f"  - ååé‡: {throughput:.2f} æ¬¡è¿­ä»£/å°æ—¶\n")
        
        f.write(f"  - GPUæ•°é‡: {timing_stats['num_gpus']}\n")
        f.write(f"  - GPUåˆ©ç”¨ç‡ä¼°ç®—: {timing_stats.get('gpu_utilization_estimate', 'N/A')}\n\n")
        
        f.write("â° æ—¶é—´æˆ³:\n")
        f.write(f"  - å¼€å§‹æ—¶é—´: {timing_stats['start_time']}\n")
        f.write(f"  - ç»“æŸæ—¶é—´: {timing_stats['end_time']}\n")
        
    print(f"âœ… è®¡æ—¶æŠ¥å‘Šå·²ä¿å­˜: {timing_report_path}")

def print_timing_summary(timing_stats: dict):
    """æ‰“å°è®¡æ—¶æ‘˜è¦"""
    print("\n" + "="*60)
    print("â±ï¸  è¿è¡Œæ—¶é—´ç»Ÿè®¡")
    print("="*60)
    
    print(f"\nğŸ• æ€»è¿è¡Œæ—¶é—´: {Timer.format_time(timing_stats['total_time'])}")
    
    print(f"\nğŸ“Š å„é˜¶æ®µè€—æ—¶:")
    # âœ… æ·»åŠ å®‰å…¨æ£€æŸ¥
    if 'initialization_time' in timing_stats:
        print(f"  1ï¸âƒ£  åˆå§‹åŒ–é˜¶æ®µ: {Timer.format_time(timing_stats['initialization_time'])} "
              f"({timing_stats['initialization_time']/timing_stats['total_time']*100:.1f}%)")
    
    if 'forest_init_time' in timing_stats:
        print(f"  2ï¸âƒ£  æ£®æ—åˆå§‹åŒ–: {Timer.format_time(timing_stats['forest_init_time'])} "
              f"({timing_stats['forest_init_time']/timing_stats['total_time']*100:.1f}%)")
    
    if 'search_time' in timing_stats:
        print(f"  3ï¸âƒ£  æœç´¢æ‰§è¡Œ:   {Timer.format_time(timing_stats['search_time'])} "
              f"({timing_stats['search_time']/timing_stats['total_time']*100:.1f}%)")
    
    if 'save_time' in timing_stats:
        print(f"  4ï¸âƒ£  ç»“æœä¿å­˜:   {Timer.format_time(timing_stats['save_time'])} "
              f"({timing_stats['save_time']/timing_stats['total_time']*100:.1f}%)")
    
    print(f"\nğŸ“ˆ æœç´¢æ•ˆç‡:")
    print(f"  - æ€»è¿­ä»£æ¬¡æ•°: {timing_stats['total_iterations']}")
    print(f"  - å¹³å‡æ¯æ¬¡è¿­ä»£: {Timer.format_time(timing_stats['avg_iteration_time'])}")
    
    if timing_stats['total_iterations'] > 0:
        throughput = 3600 / timing_stats['avg_iteration_time']
        print(f"  - ååé‡: {throughput:.2f} æ¬¡è¿­ä»£/å°æ—¶")
    
    print(f"  - GPUæ•°é‡: {timing_stats['num_gpus']}")
    
    # ä¼°ç®—GPUåˆ©ç”¨ç‡
    if timing_stats['num_gpus'] > 0:
        ideal_time = timing_stats['search_time'] / timing_stats['num_gpus']
        actual_avg_time = timing_stats['avg_iteration_time']
        utilization = (ideal_time / actual_avg_time) * 100 if actual_avg_time > 0 else 0
        print(f"  - GPUåˆ©ç”¨ç‡ä¼°ç®—: {utilization:.1f}%")
        timing_stats['gpu_utilization_estimate'] = f"{utilization:.1f}%"
    
    print(f"\nâ° æ—¶é—´èŒƒå›´:")
    print(f"  å¼€å§‹: {timing_stats['start_time']}")
    print(f"  ç»“æŸ: {timing_stats['end_time']}")
    
    print("="*60)

def print_final_results(search, timing_stats: dict):
    """æ‰“å°æœ€ç»ˆç»“æœ"""
    print("\n" + "="*60)
    print("ğŸ‰ æœç´¢å®Œæˆ! æœ€ç»ˆç»“æœ:")
    print("="*60)
    
    best_model = search.get_best_model()
    stats = search.get_search_statistics()
    
    if best_model:
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹:")
        print(f"   - å¥–åŠ±: {stats['best_reward']:.4f}")
        print(f"   - é…ç½®ID: {best_model.candidate_id if hasattr(best_model, 'candidate_id') else 'N/A'}")
        
        print(f"\nğŸ“Š æœç´¢ç»Ÿè®¡:")
        print(f"   - æ€»è¿­ä»£æ¬¡æ•°: {stats['iterations']}")
        print(f"   - å”¯ä¸€é…ç½®: {stats['unique_configs']}")
        print(f"   - é‡å¤æ¬¡æ•°: {stats['duplicate_count']}")
        print(f"   - é‡å¤ç‡: {stats['duplicate_count']/(stats['iterations']+stats['duplicate_count'])*100:.1f}%")
        
        print(f"\nğŸŒ³ æœç´¢æ ‘ç»Ÿè®¡:")
        print(f"   - æ€»èŠ‚ç‚¹æ•°: {stats['tree_statistics']['total_nodes']}")
        print(f"   - è¯„ä¼°èŠ‚ç‚¹: {stats['tree_statistics']['evaluated_nodes']}")
        print(f"   - æ£®æ—å¤§å°: {stats['tree_statistics']['forest_count']}")
        print(f"   - å¹³å‡å¥–åŠ±: {stats['tree_statistics']['average_reward']:.4f}")
        print(f"   - æœ€ä½³å¥–åŠ±: {stats['tree_statistics']['best_reward']:.4f}")
        
        print(f"\nğŸ” å…¨å±€ç»éªŒæ´å¯Ÿ:")
        insights = stats['global_insights']
        if insights:
            for direction, insight in insights.items():
                if direction.startswith('direction_'):
                    direction_name = direction.replace('direction_', '')
                    success_rate = insight.get('success_rate', 0)
                    avg_reward = insight.get('average_reward', 0)
                    visit_count = insight.get('visit_count', 0)
                    print(f"   - {direction_name:6s}: è®¿é—®={visit_count:3d}, "
                          f"æˆåŠŸç‡={success_rate:.1%}, å¹³å‡å¥–åŠ±={avg_reward:.3f}")
        else:
            print("   (æš‚æ— æ´å¯Ÿæ•°æ®)")
    
    # æ‰“å°è®¡æ—¶æ‘˜è¦
    print_timing_summary(timing_stats)
    
    print("\n" + "="*60)

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¹¶è¡Œæ•£å°„æ£®æ—æœç´¢ï¼ˆé˜Ÿåˆ—ç‰ˆæœ¬ï¼‰")
    parser.add_argument("--dataset", type=str, default="MMAct", 
                       choices=["MMAct", "Mhealth", "Wharf", "UTD-MHAD", "USCHAD"], 
                       help="æ•°æ®é›†åç§°")
    parser.add_argument("--iterations", type=int, default=50, 
                       help="æœç´¢è¿­ä»£æ¬¡æ•°")
    parser.add_argument("--num_seeds", type=int, default=4,
                       help="åˆå§‹ç§å­æ•°é‡")
    parser.add_argument("--num_gpus", type=int, default=4,
                       help="ä½¿ç”¨çš„GPUæ•°é‡")
    parser.add_argument("--train_epochs", type=int, default=100,
                       help="æ¯ä¸ªæ¨¡å‹çš„è®­ç»ƒè½®æ•°")
    parser.add_argument("--exploration_weight", type=float, default=1.414, 
                       help="æ¢ç´¢æƒé‡")
    parser.add_argument("--experiment_name", type=str, default="sfs_queue", 
                       help="å®éªŒåç§°")
    
    args = parser.parse_args()
    
    # è®°å½•å¼€å§‹æ—¶é—´
    experiment_start_time = time.time()
    start_datetime = datetime.now()
    
    print("ğŸš€ å¼€å§‹å¹¶è¡Œæ•£å°„æ£®æ—æœç´¢ï¼ˆé˜Ÿåˆ—ç‰ˆæœ¬ï¼‰...")
    print(f"â° å¼€å§‹æ—¶é—´: {start_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"\nğŸ“‹ å®éªŒé…ç½®:")
    print(f"   - æ•°æ®é›†: {args.dataset}")
    print(f"   - è¿­ä»£æ¬¡æ•°: {args.iterations}")
    print(f"   - åˆå§‹ç§å­: {args.num_seeds}")
    print(f"   - GPUæ•°é‡: {args.num_gpus}")
    print(f"   - è®­ç»ƒè½®æ•°: {args.train_epochs}")
    print(f"   - æ¢ç´¢æƒé‡: {args.exploration_weight}")
    print(f"   - å®éªŒåç§°: {args.experiment_name}")
    
    # åˆå§‹åŒ–è®¡æ—¶ç»Ÿè®¡
    timing_stats = {
        'start_time': start_datetime.strftime('%Y-%m-%d %H:%M:%S'),
        'num_gpus': args.num_gpus,
        'total_iterations': args.iterations,
    }
    
    # è®¾ç½®æœç´¢ç©ºé—´å’Œçº¦æŸ
    print("\nâ±ï¸  [1/4] åˆå§‹åŒ–é˜¶æ®µ...")
    with Timer("initialization") as init_timer:
        search_space, constraints = setup_search_space(args.dataset)
        output_dir = create_output_directory(args.experiment_name)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    timing_stats['initialization_time'] = init_timer.elapsed
    print(f"   âœ… åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {init_timer.get_elapsed_str()}")
    
    try:
        # åˆ›å»ºå¹¶è¡Œæœç´¢å®ä¾‹
        search = create_parallel_sfs_search(
            search_space=search_space,
            constraints=constraints,
            dataset_name=args.dataset,
            num_gpus=args.num_gpus,
            exploration_weight=args.exploration_weight
        )
        
        # åˆå§‹åŒ–æ£®æ—ï¼ˆä¼šå¯åŠ¨å·¥ä½œè¿›ç¨‹ï¼‰
        print(f"\nâ±ï¸  [2/4] æ£®æ—åˆå§‹åŒ–é˜¶æ®µ ({args.num_seeds} ä¸ªç§å­)...")
        forest_init_start = time.time()
        with Timer("forest_init") as forest_timer:
            search.initialize_forest(num_seeds=args.num_seeds)
        
        timing_stats['forest_init_time'] = forest_timer.elapsed
        timing_stats['avg_seed_time'] = forest_timer.elapsed / args.num_seeds
        print(f"   âœ… æ£®æ—åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {forest_timer.get_elapsed_str()}")
        print(f"   ğŸ“Š å¹³å‡æ¯ä¸ªç§å­: {Timer.format_time(timing_stats['avg_seed_time'])}")
        
        # æ‰§è¡Œæœç´¢
        print(f"\nâ±ï¸  [3/4] æœç´¢æ‰§è¡Œé˜¶æ®µ ({args.iterations} æ¬¡è¿­ä»£)...")
        print(f"   é¢„è®¡æ—¶é—´: {Timer.format_time(timing_stats['avg_seed_time'] * args.iterations)}")
        
        with Timer("search") as search_timer:
            search.search(
                iterations=args.iterations,
                exploration_weight=args.exploration_weight,
                dataset_names=[args.dataset]
            )
        
        timing_stats['search_time'] = search_timer.elapsed
        timing_stats['avg_iteration_time'] = search_timer.elapsed / args.iterations
        print(f"   âœ… æœç´¢å®Œæˆï¼Œè€—æ—¶: {search_timer.get_elapsed_str()}")
        print(f"   ğŸ“Š å¹³å‡æ¯æ¬¡è¿­ä»£: {Timer.format_time(timing_stats['avg_iteration_time'])}")
        
        # ä¿å­˜ç»“æœ
        print(f"\nâ±ï¸  [4/4] ä¿å­˜ç»“æœ...")
        with Timer("save") as save_timer:
            timing_stats['save_time'] = 0  # âœ… å…ˆè®¾ç½®å ä½å€¼
            # è®¡ç®—æ€»æ—¶é—´
            timing_stats['total_time'] = time.time() - experiment_start_time
            timing_stats['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            save_search_results(search, output_dir, vars(args), timing_stats)
        
        timing_stats['save_time'] = save_timer.elapsed
        print(f"   âœ… ç»“æœä¿å­˜å®Œæˆï¼Œè€—æ—¶: {save_timer.get_elapsed_str()}")
        
        # æ‰“å°æœ€ç»ˆç»“æœï¼ˆåŒ…å«è®¡æ—¶ä¿¡æ¯ï¼‰
        print_final_results(search, timing_stats)
        
        # æ‰“å°æ€»ç»“
        total_time = time.time() - experiment_start_time
        end_datetime = datetime.now()
        
        print(f"\nâœ… å®éªŒå®Œæˆ!")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
        print(f"â° ç»“æŸæ—¶é—´: {end_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"â±ï¸  æ€»è€—æ—¶: {Timer.format_time(total_time)}")
        
        # ä¼°ç®—å¦‚æœè¿è¡Œæ›´å¤šè¿­ä»£éœ€è¦çš„æ—¶é—´
        if args.iterations < 100:
            estimated_100 = (timing_stats['avg_iteration_time'] * 100) + timing_stats['forest_init_time']
            print(f"\nğŸ’¡ æç¤º: å¦‚æœè¿è¡Œ100æ¬¡è¿­ä»£ï¼Œé¢„è®¡éœ€è¦: {Timer.format_time(estimated_100)}")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­å®éªŒ")
        timing_stats['total_time'] = time.time() - experiment_start_time
        timing_stats['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        timing_stats['interrupted'] = True
        print(f"â±ï¸  å·²è¿è¡Œæ—¶é—´: {Timer.format_time(timing_stats['total_time'])}")
        
    except Exception as e:
        print(f"\nâŒ æœç´¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
        timing_stats['total_time'] = time.time() - experiment_start_time
        timing_stats['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        timing_stats['error'] = str(e)
        
    finally:
        # ç¡®ä¿å·¥ä½œè¿›ç¨‹è¢«æ¸…ç†
        print("\nğŸ§¹ æ¸…ç†èµ„æº...")
        
        # æ‰“å°æœ€ç»ˆè®¡æ—¶
        if 'total_time' not in timing_stats:
            timing_stats['total_time'] = time.time() - experiment_start_time
            timing_stats['end_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

if __name__ == "__main__":
    main()