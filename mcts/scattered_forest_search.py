# models/scattered_forest_search.py
import uuid
import json
import hashlib
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from .mcts_nodes import MCTSNode, MCTSTree
from .config_generator import ConfigGenerator, ScatteringGenerator
from .evaluator import ModelEvaluator
from models import CandidateModel
from llm_prompt import LLMConfigGenerator
from utils import calculate_memory_usage
from data import get_dataset_info, get_multitask_dataloaders


class ScatteredForestSearch:
    """æ•£å°„æ£®æ—æœç´¢ç®—æ³•"""
    
    def __init__(self, search_space: Dict[str, Any], constraints: Dict[str, float], dataset_name: str,
                 device: str = "cuda", exploration_weight: float = 1.414):
        self.search_space = search_space
        self.constraints = constraints
        self.device = device
        self.exploration_weight = exploration_weight
        
        self.dataset_info = get_dataset_info(dataset_name)

        multitask_dataloaders = get_multitask_dataloaders(root_dir="/root/har_train/data/UniMTS_data", datasets=[dataset_name])
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸåŠ è½½äº†æŒ‡å®šæ•°æ®é›†
        if dataset_name not in multitask_dataloaders:
            available_datasets = list(multitask_dataloaders.keys())
            raise ValueError(f"æ•°æ®é›† {dataset_name} åŠ è½½å¤±è´¥ã€‚å¯ç”¨çš„æ•°æ®é›†: {available_datasets}")
        # æå–å•ä¸ªæ•°æ®é›†çš„æ•°æ®åŠ è½½å™¨
        self.dataloader = multitask_dataloaders[dataset_name]
        print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®é›† {dataset_name}:")
        print(f"   - è®­ç»ƒé›†: {len(self.dataloader['train'].dataset)} æ ·æœ¬")
        print(f"   - æµ‹è¯•é›†: {len(self.dataloader['test'].dataset)} æ ·æœ¬")

        # æ–°å¢å†…å­˜çº¦æŸç›¸å…³å±æ€§
        self.max_memory = float(constraints.get("max_peak_memory", 20e6))/1e6  # MB
        print(f"max memory: {self.max_memory}MB")

        # åˆå§‹åŒ–ç»„ä»¶
        self.config_generator = ConfigGenerator(search_space, self.dataset_info, self.max_memory)
        self.scattering_generator = ScatteringGenerator(self.config_generator)
        self.evaluator = ModelEvaluator(constraints, device, dataloader=self.dataloader)
        self.llm_config_generator = LLMConfigGenerator(search_space, constraints, dataset_name)  # æ–°å¢

        # æœç´¢çŠ¶æ€ - ä½¿ç”¨å•ä¸ª MCTSTree ï¼ˆæ”¯æŒæ£®æ—ï¼‰
        self.tree = MCTSTree(exploration_weight=exploration_weight)
        self.best_candidate: Optional[CandidateModel] = None
        self.best_reward: float = -float('inf')
        self.iteration_count: int = 0

        # é‡åŒ–æ–¹å‘é€‰é¡¹
        self.quant_directions = ["none", "static", "qat"]

        self.max_retry_attempts = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°

        # æ–°å¢ï¼šå»é‡ç›¸å…³å±æ€§
        self.seen_configs = set()  # å­˜å‚¨å·²è§è¿‡çš„é…ç½®å“ˆå¸Œå€¼
        self.duplicate_count = 0   # é‡å¤é…ç½®è®¡æ•°

    def _generate_config_hash(self, config: Dict[str, Any]) -> str:
        """ç”Ÿæˆé…ç½®çš„å“ˆå¸Œå€¼ç”¨äºå»é‡"""
        # åˆ›å»ºä¸€ä¸ªè§„èŒƒåŒ–çš„é…ç½®å‰¯æœ¬ï¼Œç§»é™¤å¯èƒ½å˜åŒ–çš„å­—æ®µ
        normalized_config = self._normalize_config(config)
        
        # å°†é…ç½®è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²å¹¶ç”Ÿæˆå“ˆå¸Œ
        config_str = json.dumps(normalized_config, sort_keys=True, separators=(',', ':'))
        return hashlib.md5(config_str.encode()).hexdigest()
    
    def _normalize_config(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """è§„èŒƒåŒ–é…ç½®ï¼Œç§»é™¤ä¸å½±å“æ¨¡å‹ç»“æ„çš„å­—æ®µ"""
        normalized = {
            "input_channels": config.get("input_channels"),
            "num_classes": config.get("num_classes"),
            "stages": []
        }
        
        # å¤„ç†æ¯ä¸ªstage
        for stage in config.get("stages", []):
            normalized_stage = {
                "channels": stage.get("channels"),
                "blocks": []
            }
            
            # å¤„ç†æ¯ä¸ªblock
            for block in stage.get("blocks", []):
                normalized_block = {
                    "type": block.get("type"),
                    "kernel_size": block.get("kernel_size"),
                    "stride": block.get("stride"),
                    "expansion": block.get("expansion"),
                    "has_se": block.get("has_se"),
                    "se_ratio": block.get("se_ratio"),
                    "skip_connection": block.get("skip_connection"),
                    "activation": block.get("activation")
                }
                normalized_stage["blocks"].append(normalized_block)
            
            normalized["stages"].append(normalized_stage)
        
        return normalized
    
    def _is_duplicate_config(self, config: Dict[str, Any]) -> bool:
        """æ£€æŸ¥é…ç½®æ˜¯å¦é‡å¤"""
        config_hash = self._generate_config_hash(config)
        return config_hash in self.seen_configs
    
    def _add_config_to_seen(self, config: Dict[str, Any]):
        """å°†é…ç½®æ·»åŠ åˆ°å·²è§é›†åˆ"""
        config_hash = self._generate_config_hash(config)
        self.seen_configs.add(config_hash)
        
    def initialize_forest(self, num_seeds: int = 5):
        """åˆå§‹åŒ–æ£®æ—"""
        print(f"åˆå§‹åŒ–æ£®æ—: {num_seeds} ä¸ªç§å­")

        # æ¸…ç©ºå·²è§é…ç½®é›†åˆ
        self.seen_configs.clear()
        self.duplicate_count = 0
        
        # ç”Ÿæˆæ•£å°„çš„ç§å­é…ç½®
        scattered_seeds = self.scattering_generator.generate_scattered_seeds(num_seeds)
        
        for i, seed_config in enumerate(scattered_seeds):
            # æ£€æŸ¥æ˜¯å¦é‡å¤
            if self._is_duplicate_config(seed_config):
                print(f"è·³è¿‡é‡å¤çš„ç§å­é…ç½® {i}")
                self.duplicate_count += 1
                continue
            print(f"seed config:\n {seed_config}")
            candidate = CandidateModel(config=seed_config)
            # è¯„ä¼°ç§å­ rewardå°±æ˜¯å‡†ç¡®ç‡ï¼ˆ0-100èŒƒå›´ï¼‰
            reward, metrics = self.evaluator.evaluate_candidate(candidate)

            # åˆ›å»ºèŠ‚ç‚¹
            node_id = f"seed_{i}"
            node = MCTSNode(
                node_id=node_id,
                candidate=candidate,
                directions=self.quant_directions
            )
            # è¿™ä¸ªåœ°æ–¹é™¤äº†å¢åŠ  visitï¼Œè¿˜ç´¯åŠ äº† total reward
            node.update_reward(reward)
            node.is_forest_root = True

            # æ·»åŠ åˆ°æ£®æ—ä½œä¸ºæ ¹èŠ‚ç‚¹
            self.tree.add_node(node, is_forest_root=True)
            
            # ä¸ºç§å­èŠ‚ç‚¹ç”Ÿæˆæ•£å°„æ–¹å‘
            scattering_directions = self.tree.scattering(node)
            node.directions = scattering_directions

            # åˆå§‹åŒ–æ–¹å‘ç»Ÿè®¡
            for direction in scattering_directions:
                node.direction_q_values[direction] = 0.0
                node.direction_visits[direction] = 0

            # æ›´æ–°æœ€ä½³å€™é€‰
            if reward > self.best_reward:
                self.best_reward = reward
                self.best_candidate = candidate
            
            print(f"ç§å­ {node_id}: å¥–åŠ± = {reward:.4f}, "
                  f"å‡†ç¡®ç‡ = {metrics.get('accuracy', 0):.4f}")
    
    def _check_memory_constraint(self, config: Dict[str, Any]) -> Tuple[bool, float, str]:
        """æ£€æŸ¥é…ç½®çš„å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        try:
            candidate = CandidateModel(config=config)
            model = candidate.build_model()
            # è®¡ç®—å†…å­˜ä½¿ç”¨é‡
            memory_info = calculate_memory_usage(model, input_size=(64, self.dataset_info['channels'], self.dataset_info['time_steps']), device='cuda')

            
            memory_usage = memory_info["total_memory_MB"]

            # æ ¹æ®é‡åŒ–æ¨¡å¼è°ƒæ•´å†…å­˜ä½¿ç”¨é‡
            quant_mode = config.get("quant_mode", "none")
            if quant_mode in ["static", "qat"]:
                # é‡åŒ–æ¨¡å‹é€šå¸¸å¯ä»¥å‹ç¼©åˆ°åŸæ¥çš„ 1/4 å·¦å³
                compressed_memory = memory_usage / 4.0
                print(f"é‡åŒ–æ¨¡å‹å†…å­˜å‹ç¼©: {memory_usage:.2f}MB â†’ {compressed_memory:.2f}MB (quant_mode: {quant_mode})")
                memory_usage = compressed_memory

            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
            if memory_usage <= self.max_memory:
                return True, memory_usage, "OK"
            else:
                error_msg = f"å†…å­˜ä½¿ç”¨ {memory_usage:.2f}MB è¶…è¿‡é™åˆ¶ {self.max_memory}MB"
                return False, memory_usage, error_msg
                
        except Exception as e:
            print(f"å†…å­˜è®¡ç®—å¤±è´¥: {e}")
            return False, 0, f"å†…å­˜è®¡ç®—å¤±è´¥: {str(e)}"

    def search(self, iterations: int = 100, exploration_weight: float = 1.0,
               dataset_names: list = None):
        """æ‰§è¡Œæœç´¢"""
        print(f"å¼€å§‹ SFS æœç´¢: {iterations} æ¬¡è¿­ä»£")
        
        for iteration in range(iterations):
            self.iteration_count += 1

            # 1. é€‰æ‹©ç§å­èŠ‚ç‚¹ (Foresting)
            selected_seed = self.tree.select_forest_root()
            if not selected_seed:
                print("æ²¡æœ‰å¯ç”¨çš„ç§å­èŠ‚ç‚¹ï¼Œé‡æ–°åˆå§‹åŒ–æ£®æ—")
                self.initialize_forest(3)
                selected_seed = self.tree.select_forest_root()

            # 2. ä»ç§å­èŠ‚ç‚¹å¼€å§‹æ¨¡æ‹Ÿï¼Œ é€‰æ‹©è¦æ‰©å±•çš„èŠ‚ç‚¹
            current_node, trajectory = self._simulate_from_seed(selected_seed)

            # 3. Scattering é€‰æ‹©ä¼˜åŒ–æ–¹å‘
            direction = current_node.get_best_direction(self.exploration_weight)

            # 4. ä½¿ç”¨ LLM é…ç½®ç”Ÿæˆå™¨ç”Ÿæˆæ–°é…ç½®
            new_config = self._generate_config_with_llm(current_node, direction)

            # æ£€æŸ¥æ˜¯å¦é‡å¤
            if self._is_duplicate_config(new_config):
                print(f"ğŸ” è¿­ä»£ {iteration}: è·³è¿‡é‡å¤é…ç½®")
                self.duplicate_count += 1
                continue

            # 5. åˆ›å»ºæ–°å€™é€‰å¹¶è¯„ä¼°
            new_candidate = CandidateModel(config=new_config)
            reward, metrics = self.evaluator.evaluate_candidate(new_candidate, dataset_names)
            
            # 6. æ‰©å±•èŠ‚ç‚¹
            child_node = self._create_child_node(current_node, direction, new_candidate, reward)
            
            # 7. åå‘ä¼ æ’­å¥–åŠ±
            self._backpropagate(trajectory + [(current_node, direction, child_node)], reward)
            
            # 8. Scouting: æ›´æ–°å…¨å±€ç»éªŒ
            feedback = {
                "reward": reward,
                "accuracy": metrics.get('accuracy', 0),
                "direction": direction,
                "parent_config": current_node.candidate.config if current_node.candidate else {},
                "child_config": new_config
            }
            self.tree.scouting(current_node, direction, child_node, reward, feedback)

            # 9. ä¸ºå­èŠ‚ç‚¹ç”Ÿæˆæ–°çš„æ•£å°„æ–¹å‘
            scattering_directions = self.tree.scattering(child_node)
            child_node.directions = scattering_directions
            
            # æ·»åŠ åˆ°å·²è§é…ç½®
            self._add_config_to_seen(new_config)

            # æ›´æ–°æœ€ä½³å€™é€‰
            if reward > self.best_reward:
                self.best_reward = reward
                self.best_candidate = new_candidate
                print(f"ğŸ¯ è¿­ä»£ {iteration}: å‘ç°æ–°çš„æœ€ä½³å€™é€‰! "
                      f"å¥–åŠ± = {reward:.4f}, å‡†ç¡®ç‡ = {metrics.get('accuracy', 0):.4f}")
            
            if iteration % 10 == 0:
                self._print_search_progress(iteration)
    
    def _select_seed_node(self, tree: MCTSTree, exploration_weight: float) -> MCTSNode:
        """é€‰æ‹©ç§å­èŠ‚ç‚¹"""
        # ç®€å•çš„ç­–ç•¥ï¼šé€‰æ‹©è®¿é—®æ¬¡æ•°æœ€å°‘çš„èŠ‚ç‚¹è¿›è¡Œæ¢ç´¢
        min_visits = float('inf')
        selected_node = None
        
        for node in tree.nodes.values():
            if node.visit_count < min_visits:
                min_visits = node.visit_count
                selected_node = node
        
        return selected_node or list(tree.nodes.values())[0]
    
    def _simulate_from_seed(self, seed_node: MCTSNode) -> Tuple[MCTSNode, List]:
        """ä»ç§å­èŠ‚ç‚¹å¼€å§‹æ¨¡æ‹Ÿï¼Œé€‰æ‹©è¦æ‰©å±•çš„èŠ‚ç‚¹"""
        trajectory = []
        current_node = seed_node
        
        # æ¨¡æ‹Ÿç›´åˆ°æ‰¾åˆ°å¶å­èŠ‚ç‚¹æˆ–è¾¾åˆ°æœ€å¤§æ·±åº¦
        max_depth = 5
        depth = 0
        
        while depth < max_depth and current_node.children:
            # ä½¿ç”¨ UCT é€‰æ‹©æœ€ä½³æ–¹å‘
            direction = current_node.get_best_direction(self.exploration_weight)
            
            # å¦‚æœè¯¥æ–¹å‘æœ‰å­èŠ‚ç‚¹ï¼Œç»§ç»­å‰è¿›
            if direction in current_node.children:
                next_node = current_node.children[direction]
                trajectory.append((current_node, direction, next_node))
                current_node = next_node
                depth += 1
            else:
                # æ²¡æœ‰å­èŠ‚ç‚¹ï¼Œé€‰æ‹©æ‰©å±•è¿™ä¸ªèŠ‚ç‚¹
                break
        
        return current_node, trajectory
    
    def _generate_config_with_llm(self, parent_node: MCTSNode, direction: str) -> Dict[str, Any]:
        """ä½¿ç”¨ LLM é…ç½®ç”Ÿæˆå™¨ç”Ÿæˆæ–°é…ç½®"""
        parent_config = parent_node.candidate.config if parent_node.candidate else {}
        
        parent_performance = {
            "average_reward": parent_node.average_reward,
            "visit_count": parent_node.visit_count,
            "directions_explored": list(parent_node.direction_visits.keys())
        }
        
        # ä¿®å¤ï¼šä¼ é€’å…¨å±€ç»éªŒç»™ LLM
        global_insights = self.tree.global_insights

        # é‡è¯•æœºåˆ¶
        for attempt in range(self.max_retry_attempts + 1):
            try:
                # ç”Ÿæˆé…ç½®
                new_config = self.llm_config_generator.generate_config_with_context(
                    parent_config, direction, parent_performance, global_insights,
                    memory_feedback=None if attempt == 0 else memory_feedback
                )
                print(f"new config:\n {new_config}")
                # æ£€æŸ¥å†…å­˜çº¦æŸ
                memory_ok, memory_usage, memory_msg = self._check_memory_constraint(new_config)
                print(f"memory usage: {memory_usage}MB")
                # æ£€æŸ¥æ˜¯å¦é‡å¤
                if self._is_duplicate_config(new_config):
                    print(f"ğŸ”„ LLM ç”Ÿæˆé‡å¤é…ç½® (å°è¯• {attempt+1}/{self.max_retry_attempts})ï¼Œé‡æ–°ç”Ÿæˆ...")
                    memory_feedback = f"""
                    The previous model config: {json.dumps(new_config)}
                    The generated configuration is a duplicate of a previously seen model. 
                    Please generate a different architecture. This is attempt {attempt+1}/{self.max_retry_attempts}.
                    Suggestions:
                    - Change the number of stages
                    - Modify the number of blocks in stages
                    - Use different convolution types
                    - Adjust channel numbers
                    - Try different expansion ratios
                    """
                    continue

                if memory_ok:
                    print(f"âœ… é…ç½®é€šè¿‡å†…å­˜æ£€æŸ¥: {memory_usage:.2f}MB")
                    return new_config
                else:
                    print(f"âš ï¸ é…ç½®å†…å­˜è¶…æ ‡ ({attempt+1}/{self.max_retry_attempts}): {memory_msg}")
                    
                    # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œä½¿ç”¨æ™ºèƒ½é™çº§
                    if attempt == self.max_retry_attempts:
                        print("ğŸš¨ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨æ™ºèƒ½é™çº§é…ç½®")
                        return self._generate_degraded_config(parent_config, direction, memory_usage)
                    
                    # æ›´æ–°æç¤ºè¯ï¼ŒåŠ å…¥å†…å­˜åé¦ˆ
                    memory_feedback = f"""
                    The previous model config: {json.dumps(new_config)}
                    The generated model configuration memory usage is {memory_usage:.2f}MB, exceeding the maximum limit {self.max_memory}MB.
                    Please generate a lighter configuration. This is the {attempt}/{self.max_retry_attempts} retry. 
                    Suggestions:
                    - Reduce the number of stages
                    - Reduce the number of blocks per phase (blocks)
                    - Use simpler convolution types
                    - Close se module or reduce expansion ratio
                    """
                    
            except Exception as e:
                print(f"LLM configuration generation failed (Attempt {attempt+1}): {e}")
                if attempt == self.max_retry_attempts:
                    return self._generate_degraded_config(parent_config, direction, 0)
        # æœ€ç»ˆå›é€€
        return self._generate_degraded_config(parent_config, direction, 0)
    
    def _generate_degraded_config(self, base_config: Dict[str, Any], direction: str, 
                            current_memory: float) -> Dict[str, Any]:
        """ç”Ÿæˆé™çº§é…ç½®ä»¥ç¡®ä¿å†…å­˜å®‰å…¨ - åŸºäºå·ç§¯ç±»å‹çš„å†…å­˜å¼€é”€ä¼˜åŒ–"""
        print("ğŸ› ï¸ ä½¿ç”¨æ™ºèƒ½é™çº§ç”Ÿæˆå®‰å…¨é…ç½®")
        
        # åŸºäºåŸºç¡€é…ç½®åˆ›å»ºå®‰å…¨ç‰ˆæœ¬
        safe_config = base_config.copy() if base_config else {}
        safe_config["quant_mode"] = direction
        
        # å¦‚æœæ²¡æœ‰åŸºç¡€é…ç½®ï¼Œç”Ÿæˆä¸€ä¸ªæœ€å°é…ç½®
        if not safe_config:
            safe_config = {
                "input_channels": self.search_space["input_channels"],
                "num_classes": self.search_space["num_classes"], 
                "quant_mode": direction,
                "stages": [
                    {
                        "blocks": [
                            {
                                "type": "SeDpConv",  # ä½¿ç”¨å†…å­˜æœ€å°çš„å·ç§¯ç±»å‹
                                "kernel_size": 3,
                                "stride": 1,
                                "expansion": 1,
                                "has_se": False,
                                "activation": "ReLU"
                            }
                        ],
                        "channels": 8
                    }
                ]
            }
            # æ£€æŸ¥æ˜¯å¦é‡å¤
            if not self._is_duplicate_config(safe_config):
                return safe_config
        
        # å°è¯•å¤šç§é™çº§ç­–ç•¥ï¼ŒåŒæ—¶é¿å…é‡å¤
        strategies = [
            self._apply_stage_reduction,
            self._apply_conv_type_optimization,
            self._apply_channel_reduction,
            self._apply_block_reduction
        ]
        
        for strategy in strategies:
            temp_config = strategy(safe_config.copy(), current_memory)
            if temp_config and not self._is_duplicate_config(temp_config):
                memory_ok, memory_usage, _ = self._check_memory_constraint(temp_config)
                if memory_ok:
                    return temp_config
                
        # æœ€ç»ˆæ‰‹æ®µ - ç”Ÿæˆç»å¯¹æœ€å°é…ç½®
        print("ğŸš¨ ç­–ç•¥5: ä½¿ç”¨ç»å¯¹æœ€å°é…ç½®")
        minimal_config = {
            "input_channels": self.dataset_info["channels"],
            "num_classes": self.dataset_info["num_classes"], 
            "quant_mode": direction,
            "stages": [
                {
                    "blocks": [
                        {
                            "type": "SeDpConv",  # å†…å­˜æœ€å°çš„å·ç§¯ç±»å‹
                            "kernel_size": 3,
                            "stride": 1,
                            "expansion": 1,
                            "has_se": False,
                            "activation": "ReLU"
                        }
                    ],
                    "channels": 8  # æœ€å°é€šé“æ•°
                }
            ]
        }

        # å¦‚æœæœ€å°é…ç½®ä¹Ÿé‡å¤ï¼Œç¨å¾®ä¿®æ”¹ä¸€ä¸‹
        attempt = 0
        while self._is_duplicate_config(minimal_config) and attempt < 10:
            # è½»å¾®ä¿®æ”¹é…ç½®ä»¥é¿å…é‡å¤
            minimal_config["stages"][0]["channels"] += 1
            attempt += 1
        
        return minimal_config

        
    def _apply_stage_reduction(self, config: Dict[str, Any], current_memory: float) -> Optional[Dict[str, Any]]:
        # ç­–ç•¥1: å¦‚æœå†…å­˜ä¸¥é‡è¶…æ ‡ï¼Œå…ˆå‡å°‘ stage æ•°é‡
        if current_memory <= self.max_memory:
            return None  # å¦‚æœå·²ç»æ»¡è¶³å†…å­˜è¦æ±‚ï¼Œä¸éœ€è¦å‡å°‘stage
        
        original_stage_count = len(config.get("stages", []))
        if original_stage_count <= 1:
            return None  # è‡³å°‘ä¿ç•™ä¸€ä¸ªstage
        
        print("ğŸ”§ ç­–ç•¥1: å‡å°‘ stage æ•°é‡")

        # ä»å½“å‰é…ç½®å¼€å§‹ï¼Œé€æ­¥å‡å°‘stageæ•°é‡
        temp_config = config.copy()
        stage_count = original_stage_count
        
        while stage_count > 1:
            # å‡å°‘ä¸€ä¸ªstage
            temp_config["stages"] = temp_config["stages"][:-1]
            stage_count -= 1
            
            # æ£€æŸ¥å†…å­˜æ˜¯å¦æ»¡è¶³
            memory_ok, new_memory, _ = self._check_memory_constraint(temp_config)
            
            if memory_ok:
                print(f"âœ… å‡å°‘ stage æ•°é‡: {original_stage_count} â†’ {stage_count}, å†…å­˜: {new_memory:.2f}MB")
                return temp_config
            else:
                print(f"âš ï¸ å‡å°‘ stage æ•°é‡: {original_stage_count} â†’ {stage_count}, å†…å­˜: {new_memory:.2f}MB (ä»è¶…æ ‡)")
                
                # å¦‚æœåªå‰©ä¸‹ä¸€ä¸ªstageè¿˜æ˜¯ä¸æ»¡è¶³ï¼Œå°±åœæ­¢
                if stage_count == 1:
                    break
        
        # å¦‚æœæ‰€æœ‰å°è¯•éƒ½ä¸æˆåŠŸï¼Œè¿”å›None
        return None
            
    def _apply_conv_type_optimization(self, config: Dict[str, Any], current_memory: float) -> Optional[Dict[str, Any]]:
        # ç­–ç•¥2: æ›¿æ¢å·ç§¯ç±»å‹ - æŒç»­æ›¿æ¢ç›´åˆ°æ»¡è¶³å†…å­˜è¦æ±‚
        if current_memory <= self.max_memory:
            return None  # å¦‚æœå·²ç»æ»¡è¶³å†…å­˜è¦æ±‚ï¼Œä¸éœ€è¦ä¼˜åŒ–
        
        print("ğŸ”§ ç­–ç•¥2: ä¼˜åŒ–å·ç§¯ç±»å‹")
        # å·ç§¯ç±»å‹çš„å†…å­˜å¼€é”€æ’åºï¼ˆä»å¤§åˆ°å°ï¼‰
        conv_type_priority = ["MBConv", "DWSepConv", "SeSepConv", "DpConv", "SeDpConv"]

        # åˆ›å»ºé…ç½®å‰¯æœ¬è¿›è¡Œæ“ä½œ
        temp_config = json.loads(json.dumps(config))  # æ·±æ‹·è´

        # ä»æœ€åä¸€ä¸ªstageå¼€å§‹å¤„ç†ï¼ˆé€šå¸¸åé¢çš„stageå‚æ•°æ›´å¤šï¼‰
        for stage_idx in range(len(temp_config.get("stages", [])) - 1, -1, -1):
            stage = temp_config["stages"][stage_idx]
            
            # å¯¹å½“å‰stageçš„æ‰€æœ‰blockè¿›è¡Œä¼˜åŒ–ï¼ˆä»åå¾€å‰ï¼‰
            for block_idx in range(len(stage.get("blocks", [])) - 1, -1, -1):
                block = stage["blocks"][block_idx]
                current_conv_type = block.get("type", "MBConv")
                
                # å¦‚æœå½“å‰ç±»å‹å·²ç»æ˜¯æœ€å°çš„ï¼Œè·³è¿‡
                if current_conv_type == "SeDpConv":
                    continue
                    
                # æ‰¾åˆ°å½“å‰ç±»å‹åœ¨ä¼˜å…ˆçº§ä¸­çš„ä½ç½®
                try:
                    current_priority = conv_type_priority.index(current_conv_type)
                except ValueError:
                    current_priority = 0
                    
                # è®°å½•åŸå§‹ç±»å‹
                original_type = block["type"]
                
                # å°è¯•æ›´å°çš„å·ç§¯ç±»å‹
                found_improvement = False
                for smaller_type in conv_type_priority[current_priority + 1:]:
                    # æ›¿æ¢ä¸ºæ›´å°çš„ç±»å‹
                    block["type"] = smaller_type
                    
                    # æ£€æŸ¥å†…å­˜
                    memory_ok, new_memory, _ = self._check_memory_constraint(temp_config)
                    
                    if memory_ok:
                        print(f"âœ… Stage{stage_idx}-Block{block_idx}: {original_type} â†’ {smaller_type}, å†…å­˜: {new_memory:.2f}MB")
                        return temp_config
                    else:
                        print(f"âš ï¸ Stage{stage_idx}-Block{block_idx}: {original_type} â†’ {smaller_type}, å†…å­˜: {new_memory:.2f}MB (ä»è¶…æ ‡)")
                        # ä¿ç•™è¿™ä¸ªæ›¿æ¢ï¼Œç»§ç»­å°è¯•å…¶ä»–block
                        found_improvement = True
                        break  # æ‰¾åˆ°ä¸€ä¸ªå¯æ›¿æ¢çš„ç±»å‹å°±ç»§ç»­ï¼Œä¸å°è¯•æ›´å°çš„ç±»å‹
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¯æ›¿æ¢çš„ç±»å‹ï¼Œæ¢å¤åŸå§‹ç±»å‹
                if not found_improvement:
                    block["type"] = original_type
                
                # æ£€æŸ¥å½“å‰çŠ¶æ€æ˜¯å¦æ»¡è¶³å†…å­˜è¦æ±‚ï¼ˆç´¯ç§¯æ›¿æ¢çš„æ•ˆæœï¼‰
                memory_ok, new_memory, _ = self._check_memory_constraint(temp_config)
                if memory_ok:
                    print(f"âœ… ç»è¿‡å¤šæ¬¡æ›¿æ¢åå†…å­˜è¾¾æ ‡: {new_memory:.2f}MB")
                    return temp_config
        
        # å¦‚æœæ‰€æœ‰æ›¿æ¢å°è¯•éƒ½ä¸æˆåŠŸï¼Œè¿”å›None
        return None
    
    def _apply_channel_reduction(self, config: Dict[str, Any], current_memory: float) -> Optional[Dict[str, Any]]:
        # ç­–ç•¥3: å¦‚æœè¿˜æ˜¯è¶…æ ‡ï¼Œå‡å°‘é€šé“æ•°ï¼ˆä»æœ€åä¸€ä¸ªstageå¼€å§‹ï¼‰
        print("ğŸ”§ ç­–ç•¥3: å‡å°‘é€šé“æ•°")
        for stage_idx in range(len(config.get("stages", [])) - 1, -1, -1):
            stage = config["stages"][stage_idx]
            original_channels = stage["channels"]
            
            # å°è¯•é€æ­¥å‡å°‘é€šé“æ•°
            for reduction_factor in [0.75, 0.5, 0.25]:
                new_channels = max(8, int(original_channels * reduction_factor))
                if new_channels == stage["channels"]:
                    continue
                    
                stage["channels"] = new_channels
                
                # æ£€æŸ¥å†…å­˜
                memory_ok, new_memory, _ = self._check_memory_constraint(config)
                
                if memory_ok:
                    print(f"âœ… Stage{stage_idx}é€šé“æ•°: {original_channels} â†’ {new_channels}, å†…å­˜: {new_memory:.2f}MB")
                    return config
                else:
                    print(f"âš ï¸ Stage{stage_idx}é€šé“æ•°: {original_channels} â†’ {new_channels}, å†…å­˜: {new_memory:.2f}MB (ä»è¶…æ ‡)")
            
            # æ¢å¤åŸå§‹é€šé“æ•°
            stage["channels"] = original_channels
        return None
    
    def _apply_block_reduction(self, config: Dict[str, Any], current_memory: float) -> Optional[Dict[str, Any]]:
        """åº”ç”¨blockå‡å°‘ç­–ç•¥ - æ¿€è¿›å‡å°‘ç›´åˆ°æ»¡è¶³å†…å­˜è¦æ±‚"""
        if current_memory <= self.max_memory:
            return None
            
        print("ğŸ”§ ç­–ç•¥4: å‡å°‘ block æ•°é‡")
        
        # åˆ›å»ºé…ç½®å‰¯æœ¬è¿›è¡Œæ“ä½œ
        temp_config = json.loads(json.dumps(config))
        
        # è®°å½•åŸå§‹é…ç½®ä¿¡æ¯
        original_stages = len(temp_config["stages"])
        
        # ä»æœ€åä¸€ä¸ªstageå¼€å§‹å¤„ç†
        for stage_idx in range(len(temp_config["stages"]) - 1, -1, -1):
            stage = temp_config["stages"][stage_idx]
            original_block_count = len(stage["blocks"])
            
            if original_block_count <= 1:
                # å¦‚æœè¿™ä¸ªstageåªæœ‰ä¸€ä¸ªblockï¼Œè€ƒè™‘åˆ é™¤æ•´ä¸ªstage
                if stage_idx > 0:  # ä¸èƒ½åˆ é™¤ç¬¬ä¸€ä¸ªstage
                    print(f"ğŸ”„ Stage{stage_idx} åªæœ‰ä¸€ä¸ªblockï¼Œå°è¯•åˆ é™¤æ•´ä¸ªstage")
                    deleted_stage = temp_config["stages"].pop(stage_idx)
                    
                    # æ£€æŸ¥å†…å­˜
                    memory_ok, new_memory, _ = self._check_memory_constraint(temp_config)
                    
                    if memory_ok:
                        print(f"âœ… åˆ é™¤ Stage{stage_idx} åå†…å­˜è¾¾æ ‡: {new_memory:.2f}MB")
                        return temp_config
                    else:
                        print(f"âš ï¸ åˆ é™¤ Stage{stage_idx} åå†…å­˜ä»è¶…æ ‡: {new_memory:.2f}MB")
                        # ä¿ç•™åˆ é™¤ç»“æœï¼Œç»§ç»­å°è¯•
                        continue
                else:
                    continue  # ç¬¬ä¸€ä¸ªstageä¸èƒ½åˆ é™¤
            
            # é€æ­¥å‡å°‘å½“å‰stageçš„blockæ•°é‡
            for new_block_count in range(original_block_count - 1, 0, -1):
                stage["blocks"] = stage["blocks"][:new_block_count]
                
                # æ£€æŸ¥å†…å­˜
                memory_ok, new_memory, _ = self._check_memory_constraint(temp_config)
                
                if memory_ok:
                    print(f"âœ… Stage{stage_idx} blockæ•°: {original_block_count} â†’ {new_block_count}, å†…å­˜: {new_memory:.2f}MB")
                    return temp_config
                else:
                    print(f"âš ï¸ Stage{stage_idx} blockæ•°: {original_block_count} â†’ {new_block_count}, å†…å­˜: {new_memory:.2f}MB (ä»è¶…æ ‡)")
                    
                    # å¦‚æœå‡å°‘åˆ°1ä¸ªblockè¿˜ä¸æ»¡è¶³ï¼Œè€ƒè™‘åˆ é™¤è¿™ä¸ªstage
                    if new_block_count == 1 and stage_idx > 0:
                        print(f"ğŸ”„ Stage{stage_idx} å‡å°‘åˆ°1ä¸ªblockä»ä¸æ»¡è¶³ï¼Œå°è¯•åˆ é™¤æ•´ä¸ªstage")
                        deleted_stage = temp_config["stages"].pop(stage_idx)
                        
                        # æ£€æŸ¥å†…å­˜
                        memory_ok, new_memory, _ = self._check_memory_constraint(temp_config)
                        
                        if memory_ok:
                            print(f"âœ… åˆ é™¤ Stage{stage_idx} åå†…å­˜è¾¾æ ‡: {new_memory:.2f}MB")
                            return temp_config
                        else:
                            print(f"âš ï¸ åˆ é™¤ Stage{stage_idx} åå†…å­˜ä»è¶…æ ‡: {new_memory:.2f}MB")
                            # ä¿ç•™åˆ é™¤ç»“æœï¼Œç»§ç»­å¤„ç†å…¶ä»–stage
                            break  # è·³å‡ºå½“å‰stageçš„å¾ªç¯ï¼Œå¤„ç†ä¸‹ä¸€ä¸ªstage
        
        # æœ€ç»ˆæ£€æŸ¥ï¼šå¦‚æœç»è¿‡æ‰€æœ‰æ“ä½œåæ»¡è¶³è¦æ±‚
        memory_ok, new_memory, _ = self._check_memory_constraint(temp_config)
        if memory_ok:
            print(f"âœ… æœ€ç»ˆå‡å°‘åå†…å­˜è¾¾æ ‡: {new_memory:.2f}MB")
            return temp_config
        
        # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œå°è¯•æç«¯æƒ…å†µï¼šåªä¿ç•™ç¬¬ä¸€ä¸ªstageçš„ç¬¬ä¸€ä¸ªblock
        if len(temp_config["stages"]) > 1 or len(temp_config["stages"][0]["blocks"]) > 1:
            print("ğŸš¨ å°è¯•æç«¯æƒ…å†µï¼šåªä¿ç•™ç¬¬ä¸€ä¸ªstageçš„ç¬¬ä¸€ä¸ªblock")
            minimal_config = {
                "input_channels": temp_config["input_channels"],
                "num_classes": temp_config["num_classes"],
                "quant_mode": temp_config["quant_mode"],
                "stages": [
                    {
                        "blocks": [temp_config["stages"][0]["blocks"][0]],
                        "channels": temp_config["stages"][0]["channels"]
                    }
                ]
            }
            
            memory_ok, new_memory, _ = self._check_memory_constraint(minimal_config)
            if memory_ok:
                print(f"âœ… æç«¯ç®€åŒ–åå†…å­˜è¾¾æ ‡: {new_memory:.2f}MB")
                return minimal_config
        
        return None
        
        # # éªŒè¯æœ€å°é…ç½®çš„å†…å­˜
        # memory_ok, final_memory, _ = self._check_memory_constraint(minimal_config)
        # if memory_ok:
        #     print(f"âœ… æœ€å°é…ç½®å†…å­˜è¾¾æ ‡: {final_memory:.2f}MB")
        #     return minimal_config
        # else:
        #     print(f"âŒ è­¦å‘Š: å³ä½¿æœ€å°é…ç½®ä¹Ÿè¶…æ ‡: {final_memory:.2f}MB")
        #     return minimal_config  # ä»ç„¶è¿”å›ï¼Œè®©è¯„ä¼°å™¨å¤„ç†
    
    def _create_child_node(self, parent_node: MCTSNode, direction: str, 
                          candidate: CandidateModel, reward: float) -> MCTSNode:
        """åˆ›å»ºå­èŠ‚ç‚¹"""
        child_node_id = f"iter_{self.iteration_count}_dir_{direction}"
        child_node = MCTSNode(
            node_id=child_node_id,
            candidate=candidate,
            directions=parent_node.directions.copy()
        )
        child_node.update_reward(reward)
        
        # æ·»åŠ åˆ°æ ‘ä¸­
        self.tree.add_node(child_node, parent_node, direction)
        
        return child_node
    
    def _backpropagate(self, trajectory: List, reward: float):
        """åå‘ä¼ æ’­å¥–åŠ±"""
        # æ²¿ç€è½¨è¿¹å‘ä¸Šä¼ æ’­
        current_reward = reward

        for i, (node, direction, next_node) in enumerate(reversed(trajectory)):
            # æ›´æ–°æ–¹å‘ç»Ÿè®¡
            node.update_direction_stats(direction, current_reward)
            
            # ä½¿ç”¨ max ç­–ç•¥æ›´æ–° Q å€¼ï¼ˆè®ºæ–‡å…¬å¼2ï¼‰
            current_q = node.direction_q_values.get(direction, 0.0)
            
            # è·å–ä¸‹ä¸€èŠ‚ç‚¹çš„æœ€å¤§ Q å€¼
            next_max_q = 0.0
            if next_node and next_node.direction_q_values:
                next_max_q = max(next_node.direction_q_values.values())
            
            new_q = max(current_q, next_max_q)
            
            # åŠ æƒå¹³å‡æ›´æ–°ï¼ˆè®ºæ–‡å…¬å¼2ï¼‰
            visits = node.direction_visits.get(direction, 0)
            alpha = 1.0 / (visits + 1) if visits > 0 else 1.0
            updated_q = (1 - alpha) * current_q + alpha * new_q
            
            node.direction_q_values[direction] = updated_q
            
            # åŒæ—¶æ›´æ–°èŠ‚ç‚¹çš„æ€»å¥–åŠ±ï¼ˆå¸¦è¡°å‡ï¼‰
            node.update_reward(current_reward)
            current_reward = node.average_reward * 0.9  # è¡°å‡å› å­
    
    def _print_search_progress(self, iteration: int):
        """æ‰“å°æœç´¢è¿›åº¦"""
        stats = self.tree.get_graph_statistics()
        
        print(f"\n--- è¿­ä»£ {iteration} è¿›åº¦æŠ¥å‘Š ---")
        print(f"æœ€ä½³å¥–åŠ±: {self.best_reward:.4f}")
        print(f"æ€»èŠ‚ç‚¹æ•°: {stats['total_nodes']}")
        print(f"è¯„ä¼°èŠ‚ç‚¹: {stats['evaluated_nodes']}")
        print(f"æ£®æ—å¤§å°: {stats['forest_count']} æ£µæ ‘")
        print(f"å¹³å‡å¥–åŠ±: {stats['average_reward']:.4f}")
        print(f"å…¨å±€ç»éªŒæ•°: {stats['global_insights_count']}")
        print("------------------------------\n")

        # æ˜¾ç¤ºå…¨å±€ç»éªŒ
        print("å…¨å±€ç»éªŒ:")
        for direction, insight in self.tree.global_insights.items():
            success_rate = insight.get('success_rate', 0)
            avg_reward = insight.get('average_reward', 0)
            print(f"  {direction}: æˆåŠŸç‡={success_rate:.3f}, å¹³å‡å¥–åŠ±={avg_reward:.3f}")
        
        print("------------------------------\n")
    
    def get_best_model(self) -> Optional[CandidateModel]:
        """è·å–æœ€ä½³æ¨¡å‹"""
        return self.best_candidate
    
    def get_search_statistics(self) -> Dict[str, Any]:
        """è·å–æœç´¢ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.tree.get_graph_statistics()
        
        return {
            "iterations": self.iteration_count,
            "best_reward": self.best_reward,
            "tree_statistics": stats,
            "global_insights": self.tree.global_insights,
            "unique_configs": len(self.seen_configs),
            "duplicate_count": self.duplicate_count
        }
    
    def save_search_state(self, filepath: str):
        """ä¿å­˜æœç´¢çŠ¶æ€"""
        self.tree.save_graph_info(filepath)

def create_sfs_search(search_space: Dict[str, Any], constraints: Dict[str, float], 
                     device: str = "cuda", exploration_weight: float = 1.414, dataset_name: str = "MMAct") -> ScatteredForestSearch:
    """åˆ›å»ºSFSæœç´¢å®ä¾‹çš„å·¥å‚å‡½æ•°"""
    return ScatteredForestSearch(
        search_space=search_space,
        constraints=constraints,
        device=device,
        exploration_weight=exploration_weight,
        dataset_name=dataset_name
    )