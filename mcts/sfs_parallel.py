"""
åŸºäºé˜Ÿåˆ—çš„å¤šGPUå¹¶è¡Œæœç´¢ - ä¿ç•™å®Œæ•´MCTSé€»è¾‘

æ¶æ„:
  ä¸»è¿›ç¨‹: ç»´æŠ¤æœç´¢æ ‘ï¼Œç”Ÿæˆé…ç½®ï¼Œåè°ƒå…¨å±€çŠ¶æ€
  å·¥ä½œè¿›ç¨‹: åœ¨å„ä¸ªGPUä¸Šè®­ç»ƒè¯„ä¼°æ¨¡å‹
"""
import uuid
import json
import hashlib
import numpy as np
import torch.multiprocessing as mp
from typing import List, Dict, Any, Optional, Tuple
from queue import Empty
import time
# å¯¼å…¥ä½ çš„åŸå§‹ç±»
from mcts.mcts_nodes import MCTSNode, MCTSTree
from mcts.config_generator import ConfigGenerator, ScatteringGenerator
from models import CandidateModel
from llm_prompt import LLMConfigGenerator
from utils import calculate_memory_usage
from data import get_dataset_info, get_multitask_dataloaders
from mcts import worker_process
# âœ… å¯¼å…¥é™çº§ç­–ç•¥ç®¡ç†å™¨
from mcts import ConfigDegradationManager


class ParallelScatteredForestSearch:
    """
    å¹¶è¡Œæ•£å°„æ£®æ—æœç´¢ - ä¸»è¿›ç¨‹ç‰ˆæœ¬
    
    ä¸»è¿›ç¨‹è´Ÿè´£:
      - ç»´æŠ¤æœç´¢æ ‘
      - ç”Ÿæˆé…ç½®ï¼ˆLLMè°ƒç”¨ï¼‰
      - åè°ƒå…¨å±€çŠ¶æ€
      - åˆ†é…ä»»åŠ¡åˆ°å·¥ä½œè¿›ç¨‹
    
    å·¥ä½œè¿›ç¨‹è´Ÿè´£:
      - è®­ç»ƒè¯„ä¼°æ¨¡å‹
    """
    
    def __init__(self, search_space: Dict[str, Any], constraints: Dict[str, float],
                 dataset_name: str, num_gpus: int = 4, device: str = "cuda",
                 exploration_weight: float = 1.414, train_epochs: int = 100):
        self.search_space = search_space
        self.constraints = constraints
        self.dataset_name = dataset_name
        self.num_gpus = num_gpus
        self.device = device
        self.exploration_weight = exploration_weight
        self.train_epochs = train_epochs
        
        # æ•°æ®é›†ä¿¡æ¯
        self.dataset_info = get_dataset_info(dataset_name)
        
        # å†…å­˜çº¦æŸ
        self.max_memory = float(constraints.get("max_peak_memory", 20e6))/1e6
        
        # é…ç½®ç”Ÿæˆå™¨
        self.config_generator = ConfigGenerator(search_space, self.dataset_info, self.max_memory)
        self.scattering_generator = ScatteringGenerator(self.config_generator)
        self.llm_config_generator = LLMConfigGenerator(search_space, constraints, dataset_name)
        
        # âœ… åˆå§‹åŒ–é™çº§ç­–ç•¥ç®¡ç†å™¨
        self.degradation_manager = ConfigDegradationManager(
            dataset_info=self.dataset_info,
            max_memory=self.max_memory,
            check_memory_fn=self._check_memory_constraint,
            is_duplicate_fn=self._is_duplicate_config
        )

        # æœç´¢æ ‘ï¼ˆä¸»è¿›ç¨‹ç»´æŠ¤ï¼‰
        self.tree = MCTSTree(exploration_weight=exploration_weight)
        self.best_candidate: Optional[CandidateModel] = None
        self.best_reward: float = -float('inf')
        self.iteration_count: int = 0
        
        # é‡åŒ–æ–¹å‘
        self.quant_directions = ["none", "static", "qat", "qaft"]  # æ·»åŠ qaft
        
        # å»é‡
        self.seen_configs = set()
        self.duplicate_count = 0
        self.max_retry_attempts = 3
        
        # å¤šè¿›ç¨‹ç»„ä»¶
        self.task_queue = None
        self.result_queue = None
        self.workers = []
        
        print(f"âœ… å¹¶è¡Œæœç´¢åˆå§‹åŒ–: {num_gpus} GPUs")
        print(f"ğŸ“‹ é‡åŒ–æ¨¡å¼: {', '.join(self.quant_directions)}")
    
    def _start_workers(self):
        """å¯åŠ¨å·¥ä½œè¿›ç¨‹"""
        # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•
        mp.set_start_method('spawn', force=True)
        
        # åˆ›å»ºé˜Ÿåˆ—
        self.task_queue = mp.Queue(maxsize=self.num_gpus * 2)
        self.result_queue = mp.Queue()
        
        # å¯åŠ¨å·¥ä½œè¿›ç¨‹
        for gpu_id in range(self.num_gpus):
            worker = mp.Process(
                target=worker_process,
                args=(gpu_id, self.task_queue, self.result_queue,
                      self.constraints, self.dataset_name, self.train_epochs)
            )
            worker.start()
            self.workers.append(worker)
            print(f"âœ… å¯åŠ¨ Worker-GPU{gpu_id} (PID: {worker.pid})")
    
    def _stop_workers(self):
        """åœæ­¢å·¥ä½œè¿›ç¨‹"""
        print("\nğŸ›‘ åœæ­¢å·¥ä½œè¿›ç¨‹...")
        
        # å‘é€ç»ˆæ­¢ä¿¡å·
        for _ in range(self.num_gpus):
            self.task_queue.put(None)
        
        # ç­‰å¾…è¿›ç¨‹ç»“æŸ
        for i, worker in enumerate(self.workers):
            worker.join(timeout=10)
            if worker.is_alive():
                print(f"âš ï¸  Worker-GPU{i} æœªå“åº”ï¼Œå¼ºåˆ¶ç»ˆæ­¢")
                worker.terminate()
                worker.join()
        
        print("âœ… æ‰€æœ‰å·¥ä½œè¿›ç¨‹å·²åœæ­¢")
    
    def _generate_config_hash(self, config: Dict[str, Any]) -> str:
        """ç”Ÿæˆé…ç½®å“ˆå¸Œ"""
        normalized = self._normalize_config(config)
        config_str = json.dumps(normalized, sort_keys=True, separators=(',', ':'))
        return hashlib.md5(config_str.encode()).hexdigest()
    
    def _normalize_config(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """è§„èŒƒåŒ–é…ç½®"""
        # ä¸åŸç‰ˆç›¸åŒçš„å®ç°
        normalized = {
            "input_channels": config.get("input_channels"),
            "num_classes": config.get("num_classes"),
            "stages": []
        }
        
        for stage in config.get("stages", []):
            normalized_stage = {
                "channels": stage.get("channels"),
                "blocks": []
            }
            
            for block in stage.get("blocks", []):
                normalized_block = {
                    "type": block.get("type"),
                    "kernel_size": block.get("kernel_size"),
                    "stride": block.get("stride"),
                    "expansion": block.get("expansion"),
                    "has_se": block.get("has_se"),
                    "se_ratio": block.get("se_ratio"),
                    "skip_connection": block.get("skip_connection"),
                    "activation": block.get("activation")
                }
                normalized_stage["blocks"].append(normalized_block)
            
            normalized["stages"].append(normalized_stage)
        
        return normalized
    
    def initialize_forest(self, num_seeds: int = 5):
        """åˆå§‹åŒ–æ£®æ— - ä½¿ç”¨å·¥ä½œè¿›ç¨‹æ± """
        print(f"\nğŸŒ± åˆå§‹åŒ–æ£®æ—: {num_seeds} ä¸ªç§å­")
        
        # å¯åŠ¨å·¥ä½œè¿›ç¨‹
        self._start_workers()
        
        # ç”Ÿæˆç§å­é…ç½®, æ¯ä¸ªç§å­å¯¹åº”ä¸€æ£µæ ‘ï¼Œç›¸å½“äºæ˜¯å¤šæ£µæ ‘çš„æ£®æ—ï¼Œæ¯æ£µæ ‘å¯¹åº”ä¸€ä¸ªgpu
        scattered_seeds = self.scattering_generator.generate_scattered_seeds(num_seeds)
        
        # æäº¤æ‰€æœ‰ç§å­åˆ°ä»»åŠ¡é˜Ÿåˆ—
        seed_ids = []
        for i, seed_config in enumerate(scattered_seeds):
            if self._is_duplicate_config(seed_config):
                print(f"è·³è¿‡é‡å¤ç§å­ {i}")
                continue
            
            seed_id = f"seed_{i}"
            seed_ids.append((seed_id, seed_config, i))
            self.task_queue.put((seed_id, seed_config))
            self._add_config_to_seen(seed_config)
        
        # æ”¶é›†æ‰€æœ‰ç»“æœ
        print(f"\nâ³ ç­‰å¾… {len(seed_ids)} ä¸ªç§å­è¯„ä¼°å®Œæˆ...")
        for seed_id, seed_config, i in seed_ids:
            # ä»ç»“æœé˜Ÿåˆ—è·å–
            candidate_id, reward, metrics = self.result_queue.get()
            
            # åˆ›å»ºå€™é€‰æ¨¡å‹
            candidate = CandidateModel(config=seed_config)
            candidate.candidate_id = candidate_id
            candidate.metrics = metrics
            
            # åˆ›å»ºèŠ‚ç‚¹
            node = MCTSNode(
                node_id=seed_id,
                candidate=candidate,
                directions=self.quant_directions
            )
            node.update_reward(reward)
            node.is_forest_root = True
            
            # æ·»åŠ åˆ°æ£®æ—
            self.tree.add_node(node, is_forest_root=True)
            
            # åˆå§‹åŒ–æ–¹å‘
            scattering_directions = self.tree.scattering(node)
            node.directions = scattering_directions
            for direction in scattering_directions:
                node.direction_q_values[direction] = 0.0
                node.direction_visits[direction] = 0
            
            # æ›´æ–°æœ€ä½³
            if reward > self.best_reward:
                self.best_reward = reward
                self.best_candidate = candidate
            
            print(f"âœ… ç§å­ {seed_id}: å¥–åŠ±={reward:.2f}, GPU={metrics.get('gpu_id')}")
    
    def search(self, iterations: int = 100, exploration_weight: float = 1.0, dataset_names: list = None):
        """æ‰§è¡Œæœç´¢ - ä½¿ç”¨å·¥ä½œè¿›ç¨‹æ±  æµæ°´çº¿å¹¶è¡Œæœç´¢"""
        print(f"\nğŸ” å¼€å§‹æœç´¢: {iterations} æ¬¡è¿­ä»£")

        # ===== é˜¶æ®µ1: é¢„å…ˆç”Ÿæˆä¸€æ‰¹ä»»åŠ¡å¡«æ»¡GPU =====
        pending_tasks = {}  # {candidate_id: (current_node, direction, trajectory)}
        submitted_count = 0
        max_initial_retries = 10  # é˜²æ­¢æ— é™å¾ªç¯

        while submitted_count < min(self.num_gpus, iterations) and max_initial_retries > 0:
            selected_seed = self.tree.select_forest_root()
            current_node, trajectory = self._simulate_from_seed(selected_seed)
            direction = current_node.get_best_direction(self.exploration_weight)
            
            new_config = self._generate_config_with_llm(current_node, direction)
            
            if self._is_duplicate_config(new_config):
                print(f"ğŸ” é‡å¤é…ç½®ï¼Œé‡æ–°ç”Ÿæˆ (å·²æäº¤: {submitted_count}/{self.num_gpus})")
                max_initial_retries -= 1
                continue
            
            candidate_id = f"iter_{self.iteration_count}_dir_{direction}"
            self.iteration_count += 1
            submitted_count += 1
            
            self.task_queue.put((candidate_id, new_config))
            self._add_config_to_seen(new_config)
            
            pending_tasks[candidate_id] = (current_node, direction, trajectory, new_config)
            print(f"ğŸ“¤ æäº¤ä»»åŠ¡ {candidate_id} ({submitted_count}/{min(self.num_gpus, iterations)})")

        # ===== é˜¶æ®µ2: æµæ°´çº¿æ‰§è¡Œ =====
        print(f"\nğŸ”„ é˜¶æ®µ2: æµæ°´çº¿æ‰§è¡Œ")
        completed_count = 0

        while completed_count < iterations:
            # ğŸ”µ éé˜»å¡åœ°è·å–ç»“æœ
            try:
                result_id, reward, metrics = self.result_queue.get(timeout=1)
                print(f"âœ… æ”¶åˆ°ç»“æœ {result_id} (å®Œæˆ: {completed_count+1}/{iterations})")
                
                # å¤„ç†ç»“æœ
                if result_id in pending_tasks:
                    current_node, direction, trajectory, new_config = pending_tasks.pop(result_id)
                    
                    # åˆ›å»ºå­èŠ‚ç‚¹
                    new_candidate = CandidateModel(config=new_config)
                    new_candidate.candidate_id = result_id
                    new_candidate.metrics = metrics

                    # âœ… æ–°å¢ï¼šè®°å½•å…ƒä¿¡æ¯
                    new_candidate.iteration = completed_count
                    new_candidate.parent_id = current_node.node_id
                    new_candidate.parent_direction = direction
                    new_candidate.root_seed_id = self._get_root_seed_id(current_node)
                    
                    child_node = MCTSNode(
                        node_id=result_id,
                        candidate=new_candidate,
                        directions=current_node.directions.copy()
                    )

                    # âœ… è®°å½•è¿­ä»£ä¿¡æ¯åˆ°èŠ‚ç‚¹
                    child_node.iteration = completed_count

                    child_node.update_reward(reward)
                    
                    # æ·»åŠ åˆ°æ ‘
                    self.tree.add_node(child_node, current_node, direction)
                    
                    # åå‘ä¼ æ’­
                    self._backpropagate(trajectory + [(current_node, direction, child_node)], reward)
                    
                    # Scouting
                    feedback = {
                        "reward": reward,
                        "accuracy": metrics.get('accuracy', 0),
                        "direction": direction,
                        "parent_config": current_node.candidate.config,
                        "child_config": new_config
                    }
                    self.tree.scouting(current_node, direction, child_node, reward, feedback)
                    
                    # Scattering
                    child_node.directions = self.tree.scattering(child_node)
                    
                    # æ›´æ–°æœ€ä½³
                    if reward > self.best_reward:
                        self.best_reward = reward
                        self.best_candidate = new_candidate
                        print(f"ğŸ¯ æ–°æœ€ä½³! å¥–åŠ±={reward:.2f}")
                    
                    completed_count += 1

                    # æ¯10ä¸ªä»»åŠ¡æ‰“å°ä¸€æ¬¡è¿›åº¦
                    if completed_count % 10 == 0:
                        self._print_search_progress(completed_count)
                
                # ğŸ”µ ç«‹å³ç”Ÿæˆæ–°ä»»åŠ¡è¡¥å……GPUé˜Ÿåˆ—
                if self.iteration_count < iterations:
                    retry_count = 0
                    max_retries = 5

                    while retry_count < max_retries:
                        selected_seed = self.tree.select_forest_root()
                        current_node, trajectory = self._simulate_from_seed(selected_seed)
                        direction = current_node.get_best_direction(self.exploration_weight)
                        
                        new_config = self._generate_config_with_llm(current_node, direction)
                        
                        if not self._is_duplicate_config(new_config):
                            candidate_id = f"iter_{self.iteration_count}_dir_{direction}"
                            self.iteration_count += 1
                            
                            self.task_queue.put((candidate_id, new_config))
                            self._add_config_to_seen(new_config)
                            
                            pending_tasks[candidate_id] = (current_node, direction, trajectory, new_config)
                            print(f"ğŸ“¤ è¡¥å……ä»»åŠ¡ {candidate_id} (å¾…å®Œæˆ: {iterations - completed_count})")
                            break
                        else:
                            retry_count += 1
                            self.duplicate_count += 1
                            print(f"ğŸ” é‡å¤é…ç½®ï¼Œé‡è¯• {retry_count}/{max_retries}")
                    if retry_count == max_retries:
                        print(f"âš ï¸  å¤šæ¬¡é‡è¯•ä»é‡å¤ï¼Œè·³è¿‡æœ¬æ¬¡è¡¥å……")
            
            except Empty:
                # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­ç­‰å¾…
                print(f"â³ ç­‰å¾…ç»“æœ... (å¾…å¤„ç†: {len(pending_tasks)})")
                continue
        
        print(f"\nâœ… æœç´¢å®Œæˆï¼å…±å®Œæˆ {completed_count} æ¬¡è¿­ä»£")
        self._stop_workers()
    
    def _get_root_seed_id(self, node: MCTSNode) -> str:
        """è¿½æº¯åˆ°æ ¹ç§å­"""
        current = node
        while not current.is_forest_root:
            # æ‰¾çˆ¶èŠ‚ç‚¹
            parent_found = False
            for potential_parent in self.tree.nodes.values():  # âœ… ä¿®æ­£
                if current.node_id in [c.node_id for c in potential_parent.children.values()]:
                    current = potential_parent
                    parent_found = True
                    break
            if not parent_found:
                break
        return current.node_id

    # ä»¥ä¸‹æ–¹æ³•ä¸åŸç‰ˆç›¸åŒ
    def _simulate_from_seed(self, seed_node: MCTSNode) -> Tuple[MCTSNode, List]:
        """ä»ç§å­æ¨¡æ‹Ÿï¼ˆä¸åŸç‰ˆç›¸åŒï¼‰"""
        trajectory = []
        current_node = seed_node
        max_depth = 5
        depth = 0
        
        while depth < max_depth and current_node.children:
            direction = current_node.get_best_direction(self.exploration_weight)
            
            if direction in current_node.children:
                next_node = current_node.children[direction]
                trajectory.append((current_node, direction, next_node))
                current_node = next_node
                depth += 1
            else:
                break
        
        return current_node, trajectory
    
    def _check_memory_constraint(self, config: Dict[str, Any]) -> Tuple[bool, float, str]:
        """æ£€æŸ¥é…ç½®çš„å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        try:
            candidate = CandidateModel(config=config)
            model = candidate.build_model()
            
            # è®¡ç®—å†…å­˜ä½¿ç”¨é‡
            memory_info = calculate_memory_usage(
                model, 
                input_size=(64, self.dataset_info['channels'], self.dataset_info['time_steps']), 
                device='cpu'  # ä½¿ç”¨CPUè®¡ç®—é¿å…GPUå ç”¨
            )
            
            memory_usage = memory_info["total_memory_MB"]
            
            # æ ¹æ®é‡åŒ–æ¨¡å¼è°ƒæ•´å†…å­˜ä½¿ç”¨é‡
            quant_mode = config.get("quant_mode", "none")
            if quant_mode in ["static", "qat", "qaft"]:
                # é‡åŒ–æ¨¡å‹é€šå¸¸å¯ä»¥å‹ç¼©åˆ°åŸæ¥çš„ 1/4 å·¦å³
                compressed_memory = memory_usage / 4.0
                print(f"ğŸ“¦ é‡åŒ–å‹ç¼©: {memory_usage:.2f}MB â†’ {compressed_memory:.2f}MB (æ¨¡å¼: {quant_mode})")
                memory_usage = compressed_memory
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
            if memory_usage <= self.max_memory:
                return True, memory_usage, "OK"
            else:
                error_msg = f"å†…å­˜ä½¿ç”¨ {memory_usage:.2f}MB è¶…è¿‡é™åˆ¶ {self.max_memory}MB"
                return False, memory_usage, error_msg
        
        except Exception as e:
            print(f"âš ï¸ å†…å­˜è®¡ç®—å¤±è´¥: {e}")
            return False, 0, f"å†…å­˜è®¡ç®—å¤±è´¥: {str(e)}"

    def _generate_config_with_llm(self, parent_node: MCTSNode, direction: str) -> Dict[str, Any]:
        """ ä½¿ç”¨LLMç”Ÿæˆé…ç½® - åŒ…å«å†…å­˜æ£€æŸ¥å’Œé‡è¯•æœºåˆ¶ """
        parent_config = parent_node.candidate.config if parent_node.candidate else {}
        parent_performance = {
            "average_reward": parent_node.average_reward,
            "visit_count": parent_node.visit_count,
            "directions_explored": list(parent_node.direction_visits.keys())
        }
        global_insights = self.tree.global_insights
        
        # ğŸ”µ é‡è¯•æœºåˆ¶
        memory_feedback = None
        llm_failed = False  # æ–°å¢ï¼šæ ‡è®°LLMæ˜¯å¦å¤±è´¥

        for attempt in range(self.max_retry_attempts + 1):
            # âœ… å¦‚æœLLMè¿ç»­2æ¬¡å¤±è´¥ï¼Œç›´æ¥åˆ‡æ¢åˆ°é™çº§ç­–ç•¥
            try:
                # ğŸ”µ å¦‚æœLLMå¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨é™çº§é…ç½®ï¼Œä¸å†é‡è¯•LLM
                if attempt >= 2 and (llm_failed or memory_feedback is not None):
                    print(f"âš ï¸ LLMå·²å¤±è´¥ï¼Œä½¿ç”¨é™çº§é…ç½® (å°è¯• {attempt+1}/{self.max_retry_attempts+1})")
                    # âœ… ä¿®æ­£ï¼šä¼ å…¥ä¸€ä¸ªè¶…è¿‡é™åˆ¶çš„å€¼ï¼Œè§¦å‘é™çº§ç­–ç•¥
                    # ä½¿ç”¨ max_memory * 2.0 è¡¨ç¤ºéœ€è¦å¼ºåŠ›é™çº§åˆ°å®‰å…¨èŒƒå›´
                    new_config = self.degradation_manager.generate_degraded_config(
                        parent_config, direction, self.max_memory
                    )
                else:
                    try:
                        # ğŸ”µ è°ƒç”¨LLMç”Ÿæˆé…ç½®
                        new_config = self.llm_config_generator.generate_config_with_context(
                            parent_config, direction, parent_performance, global_insights,
                            memory_feedback=memory_feedback
                        )
                        
                    except Exception as llm_e:
                        print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {llm_e}")
                        llm_failed = True
                        # âœ… ä¿®æ­£ï¼šåŒæ ·ä¼ å…¥è¶…è¿‡é™åˆ¶çš„å€¼
                        new_config = self.degradation_manager.generate_degraded_config(
                            parent_config, direction, self.max_memory
                        )
                print(f"ğŸ”§ ç”Ÿæˆé…ç½® (å°è¯• {attempt+1}/{self.max_retry_attempts+1})")

                # ğŸ”µ æ£€æŸ¥å†…å­˜çº¦æŸ
                memory_ok, memory_usage, memory_msg = self._check_memory_constraint(new_config)
                print(f"ğŸ“Š å†…å­˜ä½¿ç”¨: {memory_usage:.2f}MB (é™åˆ¶: {self.max_memory}MB)")

                # ğŸ”µ æ£€æŸ¥æ˜¯å¦é‡å¤
                if self._is_duplicate_config(new_config):
                    print(f"ğŸ” LLMç”Ÿæˆé‡å¤é…ç½® (å°è¯• {attempt+1}/{self.max_retry_attempts+1})")

                    # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œå¼ºåˆ¶ä½¿ç”¨é™çº§é…ç½®å¹¶æ·»åŠ éšæœºæ‰°åŠ¨
                    if attempt == self.max_retry_attempts:
                        print("ğŸš¨ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨å¼ºåˆ¶é™çº§é…ç½®")
                        # ä½¿ç”¨é™çº§é…ç½®ï¼Œä½†æŒ‡å®šä¸åŒçš„å†…å­˜é¢„ç®—ä»¥è·å¾—ä¸åŒçš„é…ç½®
                        import random
                        # âœ… ä¿®æ­£ï¼šä½¿ç”¨å½“å‰æµ‹é‡çš„å†…å­˜å€¼ï¼Œæˆ–è€…ä½¿ç”¨ä¸€ä¸ªç•¥é«˜äºé™åˆ¶çš„å€¼
                        fallback_memory = memory_usage if memory_usage > 0 else self.max_memory * 1.1
                        return self.degradation_manager.generate_degraded_config(
                            parent_config, direction, fallback_memory
                        )

                    memory_feedback = f"""
                    The previous model config: {json.dumps(new_config)}
                    The generated configuration is a DUPLICATE of a previously seen model. 
                    Please generate a DIFFERENT architecture. This is attempt {attempt+1}/{self.max_retry_attempts+1}.

                    Suggestions to create a unique configuration:
                    - Change the number of stages (currently: {len(new_config.get('stages', []))})
                    - Modify the number of blocks in each stage
                    - Use different convolution types (MBConv, DWSepConv, SeSepConv, DpConv, SeDpConv)
                    - Adjust channel numbers significantly
                    - Try different expansion ratios
                    - Modify SE module settings
                    """
                    continue
                
                # ğŸ”µ æ£€æŸ¥å†…å­˜æ˜¯å¦é€šè¿‡
                if memory_ok:
                    print(f"âœ… é…ç½®é€šè¿‡æ‰€æœ‰æ£€æŸ¥: {memory_usage:.2f}MB")
                    return new_config
                else:
                    print(f"âš ï¸ é…ç½®å†…å­˜è¶…æ ‡ ({attempt+1}/{self.max_retry_attempts+1}): {memory_msg}")
                
                    # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œä½¿ç”¨é™çº§é…ç½®
                    if attempt == self.max_retry_attempts:
                        print("ğŸš¨ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨é™çº§é…ç½®")
                        # âœ… è°ƒç”¨é™çº§ç®¡ç†å™¨
                        return self.degradation_manager.generate_degraded_config(
                            parent_config, direction, memory_usage
                        )

                    # âœ… æ”¹è¿›åçš„åé¦ˆï¼ˆæ›´å…·ä½“ã€æ›´æ™ºèƒ½ï¼‰
                    reduction_needed = memory_usage / self.max_memory
                    specific_suggestions = []

                    if reduction_needed > 1.5:
                        specific_suggestions.append("CRITICAL: Memory is 50%+ over limit. Reduce stages to 2-3 maximum")
                        specific_suggestions.append(f"Set all channel numbers to 8-16 range")
                    elif reduction_needed > 1.2:
                        specific_suggestions.append(f"Reduce channel numbers by ~{int((reduction_needed-1)*100)}%")
                        specific_suggestions.append("Remove 1-2 blocks from each stage")

                    # æ·»åŠ "é¿å…é‡å¤"çš„æŒ‡å¯¼
                    if attempt > 1:
                        specific_suggestions.append("âš ï¸ IMPORTANT: Previous attempts generated duplicates. Try:")
                        specific_suggestions.append("  - Use different conv types (e.g., DpConv instead of SeDpConv)")
                        specific_suggestions.append(f"  - Use unusual channel numbers (e.g., 11, 13, 19 instead of 8, 16)")
                        specific_suggestions.append("  - Vary expansion ratios (2, 3, 5 instead of common 4, 6)")


                    # æ›´æ–°åé¦ˆï¼Œè¦æ±‚å‡å°‘å†…å­˜
                    memory_feedback = f"""
                    Previous config memory: {memory_usage:.2f}MB (limit: {self.max_memory}MB)
                    Over budget by: {(reduction_needed-1)*100:.0f}%
                    
                    SPECIFIC ACTIONS REQUIRED:
                    {chr(10).join(f'{i+1}. {s}' for i, s in enumerate(specific_suggestions))}

                    Current config:\n {json.dumps(new_config, indent=2)}
                    """
            except Exception as e:
                print(f"âŒ LLMé…ç½®ç”Ÿæˆå¤±è´¥ (å°è¯• {attempt+1}): {e}")
                if attempt == self.max_retry_attempts:
                    # âœ… è°ƒç”¨é™çº§ç®¡ç†å™¨
                    return self.degradation_manager.generate_degraded_config(
                        parent_config, direction, self.max_memory
                    )
                
        # æœ€ç»ˆå›é€€
        print("ğŸš¨ æ‰€æœ‰å°è¯•å¤±è´¥ï¼Œä½¿ç”¨é™çº§é…ç½®")
        # âœ… ä¿®æ­£ï¼šä¼ å…¥è¶…è¿‡é™åˆ¶çš„å€¼è§¦å‘é™çº§
        return self.degradation_manager.generate_degraded_config(parent_config, direction, self.max_memory)
        

    def _backpropagate(self, trajectory: List, reward: float):
        """åå‘ä¼ æ’­ï¼ˆä¸åŸç‰ˆç›¸åŒï¼‰"""
        current_reward = reward
        
        for i, (node, direction, next_node) in enumerate(reversed(trajectory)):
            node.update_direction_stats(direction, current_reward)
            
            current_q = node.direction_q_values.get(direction, 0.0)
            next_max_q = 0.0
            if next_node and next_node.direction_q_values:
                next_max_q = max(next_node.direction_q_values.values())
            
            new_q = max(current_q, next_max_q)
            visits = node.direction_visits.get(direction, 0)
            alpha = 1.0 / (visits + 1) if visits > 0 else 1.0
            updated_q = (1 - alpha) * current_q + alpha * new_q
            
            node.direction_q_values[direction] = updated_q
            node.update_reward(current_reward)
            current_reward = node.average_reward * 0.9
    
    def _is_duplicate_config(self, config: Dict[str, Any]) -> bool:
        """æ£€æŸ¥é‡å¤"""
        config_hash = self._generate_config_hash(config)
        return config_hash in self.seen_configs
    
    def _add_config_to_seen(self, config: Dict[str, Any]):
        """æ·»åŠ åˆ°å·²è§é›†åˆ"""
        config_hash = self._generate_config_hash(config)
        self.seen_configs.add(config_hash)
    
    def _print_search_progress(self, iteration: int):
        """æ‰“å°è¿›åº¦"""
        stats = self.tree.get_graph_statistics()
        
        print(f"\n--- è¿­ä»£ {iteration} è¿›åº¦ ---")
        print(f"æœ€ä½³å¥–åŠ±: {self.best_reward:.4f}")
        print(f"æ€»èŠ‚ç‚¹æ•°: {stats['total_nodes']}")
        print(f"è¯„ä¼°èŠ‚ç‚¹: {stats['evaluated_nodes']}")
        print(f"é‡å¤é…ç½®: {self.duplicate_count}")
        print("----------------------------\n")
    
    def get_best_model(self) -> Optional[CandidateModel]:
        """è·å–æœ€ä½³æ¨¡å‹"""
        return self.best_candidate
    
    def get_search_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.tree.get_graph_statistics()
        return {
            "iterations": self.iteration_count,
            "best_reward": self.best_reward,
            "tree_statistics": stats,
            "global_insights": self.tree.global_insights,
            "unique_configs": len(self.seen_configs),
            "duplicate_count": self.duplicate_count
        }
    
    def save_search_state(self, filepath: str):
        """ä¿å­˜æœç´¢çŠ¶æ€"""
        self.tree.save_graph_info(filepath)


# å·¥å‚å‡½æ•°
def create_parallel_sfs_search(search_space: Dict[str, Any], constraints: Dict[str, float],
                               dataset_name: str = "MMAct", num_gpus: int = 4,
                               device: str = "cuda", exploration_weight: float = 1.414) -> ParallelScatteredForestSearch:
    """åˆ›å»ºå¹¶è¡ŒSFSæœç´¢å®ä¾‹"""
    return ParallelScatteredForestSearch(
        search_space=search_space,
        constraints=constraints,
        dataset_name=dataset_name,
        num_gpus=num_gpus,
        device=device,
        exploration_weight=exploration_weight
    )